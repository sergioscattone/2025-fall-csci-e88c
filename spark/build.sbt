name := "spark"

libraryDependencies ++= Seq(
  "org.apache.spark" %% "spark-core" % "3.5.1" % Provided,
  "org.apache.spark" %% "spark-sql"  % "3.5.1" % Provided
)

Compile / mainClass := Some("org.cscie88c.spark.SparkJob")

assembly / mainClass := Some("org.cscie88c.spark.SparkJob")
assembly / assemblyJarName := "SparkJob.jar"
assembly / test := {}
assembly / assemblyMergeStrategy := {
  case PathList("META-INF", xs @ _*) => MergeStrategy.discard
  case "application.conf"            => MergeStrategy.concat
  case x =>
    val oldStrategy = (assembly / assemblyMergeStrategy).value
    oldStrategy(x)
}
// see shading feature at https://github.com/sbt/sbt-assembly#shading
assembly / assemblyShadeRules := Seq(
  ShadeRule.rename("shapeless.**" -> "shadeshapeless.@1").inAll
)

// Fix for Spark/Java module access error in tests
Test / classLoaderLayeringStrategy := ClassLoaderLayeringStrategy.ScalaLibrary

// Allow Spark to access sun.nio.ch.DirectBuffer on Java 17+
Test / javaOptions += "--add-exports=java.base/sun.nio.ch=ALL-UNNAMED"

// Enable forking so javaOptions are respected in tests
Test / fork := true
